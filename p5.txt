{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_regression(x: list, y: list):\n",
    "    xm = np.sum(x) / len(x)\n",
    "    ym = np.sum(y) / len(y)\n",
    "    x2m = np.sum([xi**2 for xi in x]) / len(x)\n",
    "    x3m = np.sum([xi**3 for xi in x]) / len(x)\n",
    "    x4m = np.sum([xi**4 for xi in x]) / len(x)\n",
    "    xym = np.sum([xi * yi for xi, yi in zip(x, y)]) / len(x)\n",
    "    x2ym = np.sum([(xi**2) * yi for xi, yi in zip(x, y)]) / len(x)\n",
    "\n",
    "    sxx = x2m - xm**2\n",
    "    sxy = xym - xm * ym\n",
    "    sxx2 = x3m - xm*x2m\n",
    "    sx2x2 = x4m - x2m**2\n",
    "    sx2y = x2ym - x2m*ym\n",
    "\n",
    "    B = (sxy*sx2x2-sx2y*sxx2) / (sxx * sx2x2 - sxx2**2)\n",
    "    C = (sx2y * sxx - sxy*sxx2) / (sxx * sx2x2 - sxx2**2)\n",
    "    A = ym - B * xm - C * x2m\n",
    "\n",
    "    return C, B, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(x: list, y: list, lambda_param: float = 1.0):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    my_opt = tf.optimizers.SGD(0.001)\n",
    "\n",
    "    # Model creation\n",
    "    A = tf.Variable(tf.compat.v1.random_normal(shape=[1,1]))\n",
    "    b = tf.Variable(tf.compat.v1.random_normal(shape=[1,1]))\n",
    "\n",
    "    ridge_param = lambda_param\n",
    "    ridge_loss = tf.reduce_mean(tf.add(tf.square(A), tf.square(b)))\n",
    "    for i in range(1000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = tf.add(tf.reduce_mean(tf.square(y - tf.add(tf.matmul(tf.expand_dims(tf.convert_to_tensor(x), -1), A), b))), tf.multiply(ridge_param, ridge_loss))\n",
    "        grads = tape.gradient(loss, [A, b])\n",
    "        my_opt.apply_gradients(zip(grads, [A, b]))\n",
    "    return A.value().numpy()[0][0], b.value().numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(x: list, y:list, lambda_param: float = 0.9, a = None, b = None):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    my_opt = tf.optimizers.SGD(0.001)\n",
    "\n",
    "    # Model creation\n",
    "    A = tf.Variable(tf.compat.v1.random_normal(shape=[1,1])) if not a else tf.Variable(a)\n",
    "    b = tf.Variable(tf.compat.v1.random_normal(shape=[1,1]))\n",
    "\n",
    "    lasso_param = lambda_param\n",
    "    lasso_loss = tf.reduce_mean(tf.add(tf.math.abs(A), tf.math.abs(b)))\n",
    "    for i in range(1000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = tf.add(tf.reduce_mean(tf.square(y - tf.add(tf.matmul(tf.expand_dims(tf.convert_to_tensor(x), -1), A), b))), tf.multiply(lasso_param, lasso_loss))\n",
    "        grads = tape.gradient(loss, [A, b])\n",
    "        my_opt.apply_gradients(zip(grads, [A, b]))\n",
    "    return A.value().numpy()[0][0], b.value().numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x_test: list, y_test: list, a: float, b: float):\n",
    "    mae = []\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        mae.append(math.fabs(y - (a * x + b)))\n",
    "    return np.mean(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_test_function(x_test: list, y_test: list, a: float, b: float, c: float):\n",
    "    mae = []\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        mae.append(math.fabs(y - (a * x**2 + b*x + c)))\n",
    "    return np.mean(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_crossvalidation(x: list, y: list, num_folds: int = 3, lambda_param: float = 0.9, training_func = None):\n",
    "    size_of_fold = int(len(x) / num_folds)\n",
    "    train_indexes = random.sample(list(range(len(x))), size_of_fold * (num_folds - 1))\n",
    "    test_indexes = list(set(list(range(len(x)))) - set(train_indexes))\n",
    "    \n",
    "    x_train = [x[i] for i in train_indexes]\n",
    "    y_train = [y[i] for i in train_indexes]\n",
    "\n",
    "    a, b = training_func(x_train, y_train, lambda_param=lambda_param)\n",
    "\n",
    "    x_test = [x[i] for i in test_indexes]\n",
    "    y_test = [y[i] for i in test_indexes]\n",
    "\n",
    "    mae = test_function(x_test, y_test, a, b)\n",
    "\n",
    "    print(\"MAE for lambda value of {} is {} with equation {}x + {}\".format(lambda_param, mae, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[6.951975178410372, -1.649849426882663, 1.8504104571676696, 1.1249503340835183, 8.310596998296173, 7.473792823920759, 10.490513947867836, -0.7828563431881739, 3.9069054755937858, -1.5828389278670152, 1.060931647250447, 5.074974033447074]\n[58.32995888123392, 12.722003131385051, 13.424018859995464, 11.26551325415462, 79.06602246808936, 65.85757917488942, 120.05088289040961, 10.61286405406996, 25.263910395224705, 12.505379071571202, 11.125575960137548, 35.75536144016206]\n"
    }
   ],
   "source": [
    "x_train = [random.uniform(-2, 12) for _ in range(12)]\n",
    "y_train = [f(y) for y in x_train]\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-1.6284964244259093, 0.7837271096130789, 7.098382128913325, 5.629180728445034, 1.0861687085697538]\n[12.652000604367972, 10.61422818234247, 60.38702884807607, 41.68767567349696, 11.179762463476086]\n"
    }
   ],
   "source": [
    "x_test = [random.uniform(-2, 12) for _ in range(5)]\n",
    "y_test = [f(y) for y in x_test]\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Equation is 1.0000000000000062x^2 + -5.570978039934785e-14x + 10.000000000000021\nIn-sample error is  7.638334409421077e-14\nOut-of-sample error is 6.679101716144942e-14\n"
    }
   ],
   "source": [
    "a, b, c = poly_regression(x_train, y_train)\n",
    "print(\"Equation is {}x^2 + {}x + {}\".format(a, b, c))\n",
    "train_mae = poly_test_function(x_train, y_train, a, b, c) # in-sample error\n",
    "test_mae =  poly_test_function(x_test, y_test, a, b, c) # out-of-sample error\n",
    "print(\"In-sample error is  {}\".format(train_mae))\n",
    "print(\"Out-of-sample error is {}\".format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MAE for lambda value of 0.1 is 16.656368694063637 with equation 1.324318766593933x + 29.59817123413086\nMAE for lambda value of 1 is 16.566639523576463 with equation 1.2354942560195923x + 27.57843780517578\nMAE for lambda value of 10 is 34.12367302943103 with equation 0.8786637783050537x + 22.004140853881836\nMAE for lambda value of 100 is 12.29413379314262 with equation 2.562943696975708x + 27.54407501220703\n"
    }
   ],
   "source": [
    "for lambda_val in [0.1, 1, 10, 100]:\n",
    "    kfold_crossvalidation(x=x_train, y=y_train, lambda_param=lambda_val, training_func=lasso_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Equation training on all data is 1.6545040607452393x + 25.093008041381836\nIn-sample error is  21.28785859280423\nOut-of-sample error is 14.412662631822187\n"
    }
   ],
   "source": [
    "a, b = lasso_regression(x_train, y_train, lambda_param=100)\n",
    "print(\"Equation training on all data is {}x + {}\".format(a, b))\n",
    "train_mae = test_function(x_train, y_train, a, b) # in-sample error\n",
    "test_mae =  test_function(x_test, y_test, a, b) # out-of-sample error\n",
    "print(\"In-sample error is  {}\".format(train_mae))\n",
    "print(\"Out-of-sample error is {}\".format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MAE for lambda value of 0.1 is 16.300728453003888 with equation 1.7139427661895752x + 28.09674072265625\nMAE for lambda value of 1 is 15.37056213415914 with equation 1.3197273015975952x + 30.4455509185791\nMAE for lambda value of 10 is 48.71894873298017 with equation 0.6165410280227661x + 17.387094497680664\nMAE for lambda value of 100 is 12.193192507922907 with equation 2.5886151790618896x + 27.3167781829834\n"
    }
   ],
   "source": [
    "for lambda_val in [0.1, 1, 10, 100]:\n",
    "    kfold_crossvalidation(x=x_train, y=y_train, lambda_param=lambda_val, training_func=ridge_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Equation training on all data is 0.00021472683874890208x + 37.99654769897461\nIn-sample error is  28.55090053723598\nOut-of-sample error is 21.124515971190498\n"
    }
   ],
   "source": [
    "a, b = ridge_regression(x_train, y_train, lambda_param=100)\n",
    "print(\"Equation training on all data is {}x + {}\".format(a, b))\n",
    "train_mae = test_function(x_train, y_train, a, b) # in-sample error\n",
    "test_mae =  test_function(x_test, y_test, a, b) # out-of-sample error\n",
    "print(\"In-sample error is  {}\".format(train_mae))\n",
    "print(\"Out-of-sample error is {}\".format(test_mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}